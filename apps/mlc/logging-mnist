[17:23:45] /home/zeonfaiho/tvm/src/runtime/logging.cc:390: TVM_LOG_DEBUG enables VLOG statements in 'ir/transform.cc' up to level 1
[17:23:45] /home/zeonfaiho/tvm/src/runtime/logging.cc:390: TVM_LOG_DEBUG enables VLOG statements in 'relay/ir/transform.cc' up to level 1
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass RemoveUnusedFunctions
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'RemoveUnusedFunctions'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass ToBasicBlockNormalForm
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'ToBasicBlockNormalForm'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass qnn.Legalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass QnnLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'QnnLegalize'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass QnnCanonicalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'QnnCanonicalize'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass SimplifyInference
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:124: Build: SimplifyInference: Executing function pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:125: Build: SimplifyInference: Input module:
def @main(%data: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */) -> Tensor[(1, 10), float32] {
  %0 = nn.dense(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */, units=None) /* ty=Tensor[(1, 128), float32] */;
  %1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %4 = nn.relu(%3) /* ty=Tensor[(1, 128), float32] */;
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %6 = nn.dense(%5, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */, units=None) /* ty=Tensor[(1, 10), float32] */;
  %7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */;
  %8 = nn.bias_add(%7, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */;
  on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:148: Build: SimplifyInference: Output module:
def @main(%data: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */) -> Tensor[(1, 10), float32] {
  %0 = nn.dense(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */, units=None) /* ty=Tensor[(1, 128), float32] */;
  %1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %4 = nn.relu(%3) /* ty=Tensor[(1, 128), float32] */;
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %6 = nn.dense(%5, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */, units=None) /* ty=Tensor[(1, 10), float32] */;
  %7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */;
  %8 = nn.bias_add(%7, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */;
  on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyInference: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass EliminateCommonSubexpr
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'EliminateCommonSubexpr'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass CombineParallelConv2d
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'CombineParallelConv2d'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass CombineParallelDense
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'CombineParallelDense'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass CombineParallelBatchMatmul
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'CombineParallelBatchMatmul'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass FoldConstant
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'FoldConstant'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass FoldScaleAxis
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass BackwardFoldScaleAxis
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'BackwardFoldScaleAxis'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass ForwardFoldScaleAxis
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'ForwardFoldScaleAxis'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass FoldConstant
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'FoldConstant'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass SimplifyExpr
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:124: Build: SimplifyExpr: Executing function pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:125: Build: SimplifyExpr: Input module:
def @main(%data: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */) -> Tensor[(1, 10), float32] {
  %0 = nn.dense(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */, units=None) /* ty=Tensor[(1, 128), float32] */;
  %1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %4 = nn.relu(%3) /* ty=Tensor[(1, 128), float32] */;
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %6 = nn.dense(%5, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */, units=None) /* ty=Tensor[(1, 10), float32] */;
  %7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */;
  %8 = nn.bias_add(%7, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */;
  on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:148: Build: SimplifyExpr: Output module:
def @main(%data: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */) -> Tensor[(1, 10), float32] {
  %0 = nn.dense(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */, units=None) /* ty=Tensor[(1, 128), float32] */;
  %1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %4 = nn.relu(%3) /* ty=Tensor[(1, 128), float32] */;
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %6 = nn.dense(%5, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */, units=None) /* ty=Tensor[(1, 10), float32] */;
  %7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */;
  %8 = nn.bias_add(%7, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */;
  on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: SimplifyExpr: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass CanonicalizeCast
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'CanonicalizeCast'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass CanonicalizeOps
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'CanonicalizeOps'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass FlattenAtrousConv
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:124: Build: FlattenAtrousConv: Executing function pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:125: Build: FlattenAtrousConv: Input module:
def @main(%data: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */) -> Tensor[(1, 10), float32] {
  %0 = nn.dense(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */, units=None) /* ty=Tensor[(1, 128), float32] */;
  %1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %4 = nn.relu(%3) /* ty=Tensor[(1, 128), float32] */;
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %6 = nn.dense(%5, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */, units=None) /* ty=Tensor[(1, 10), float32] */;
  %7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */;
  %8 = nn.bias_add(%7, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */;
  on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:148: Build: FlattenAtrousConv: Output module:
def @main(%data: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */) -> Tensor[(1, 10), float32] {
  %0 = nn.dense(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */, units=None) /* ty=Tensor[(1, 128), float32] */;
  %1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %4 = nn.relu(%3) /* ty=Tensor[(1, 128), float32] */;
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %6 = nn.dense(%5, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */, units=None) /* ty=Tensor[(1, 10), float32] */;
  %7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */;
  %8 = nn.bias_add(%7, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */;
  on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: FlattenAtrousConv: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass FastMath
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'FastMath'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass FoldConstant
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:481: Build: skipping disabled pass 'FoldConstant'
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass PlanDevices
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass PlanDevicesRewrite
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:124: Build: PlanDevicesRewrite: Executing function pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:125: Build: PlanDevicesRewrite: Input module:
def @main(%data: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */) -> Tensor[(1, 10), float32] {
  %0 = nn.dense(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */, units=None) /* ty=Tensor[(1, 128), float32] */;
  %1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %4 = nn.relu(%3) /* ty=Tensor[(1, 128), float32] */;
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %6 = nn.dense(%5, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */, units=None) /* ty=Tensor[(1, 10), float32] */;
  %7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */;
  %8 = nn.bias_add(%7, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */;
  on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:148: Build: PlanDevicesRewrite: Output module:
def @main(%data: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0]) -> Tensor[(1, 10), float32] {
  %0 = nn.dense(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */, units=None) /* ty=Tensor[(1, 128), float32] */;
  %1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %4 = nn.relu(%3) /* ty=Tensor[(1, 128), float32] */;
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0)) /* ty=Tensor[(1, 128), float32] */;
  %6 = nn.dense(%5, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */, units=None) /* ty=Tensor[(1, 10), float32] */;
  %7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0)) /* ty=Tensor[(1, 10), float32] */;
  %8 = nn.bias_add(%7, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */;
  on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0), constrain_result=True)
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: PlanDevicesRewrite: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass PlanDevicesCheckConflicts
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: PlanDevicesCheckConflicts: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass InferType
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass PlanDevicesCore
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: PlanDevicesCore: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass FuseOps
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:124: Build: FuseOps: Executing function pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:125: Build: FuseOps: Input module:
def @main(%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = nn.dense(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */, units=None) /* ty=Tensor[(1, 128), float32] */;
  %1 = nn.bias_add(%0, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = on_device(%1, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %3 = device_copy(%2, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */;
  %4 = nn.relu(%3) /* ty=Tensor[(1, 128), float32] */;
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %6 = device_copy(%5, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */;
  %7 = nn.dense(%6, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */, units=None) /* ty=Tensor[(1, 10), float32] */;
  nn.bias_add(%7, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:148: Build: FuseOps: Output module:
def @main(%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32], %p13: Tensor[(128, 784), float32], Primitive=1) -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None)
  };
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */);
  %2 = fn (%p05: Tensor[(1, 128), float32], %p12: Tensor[(128), float32], Primitive=1) -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12)
  };
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */);
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32], Primitive=1) -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))))
  };
  %6 = %5(%4);
  %7 = fn (%p03: Tensor[(1, 128), float32], Primitive=1) -> Tensor[(1, 128), float32] {
    nn.relu(%p03)
  };
  %8 = %7(%6);
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32], Primitive=1) -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))))
  };
  %11 = %10(%9);
  %12 = fn (%p01: Tensor[(1, 128), float32], %p11: Tensor[(10, 128), float32], Primitive=1) -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None)
  };
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */);
  %14 = fn (%p0: Tensor[(1, 10), float32], %p1: Tensor[(10), float32], Primitive=1) -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1)
  };
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */)
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: FuseOps: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: InlineGlobals: Executing module pass with opt level: 1
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:124: Build: LabelOps: Executing function pass with opt level: 1
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:125: Build: LabelOps: Input module:
def @main(%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, %p13: Tensor[(128, 784), float32] /* ty=Tensor[(128, 784), float32] */, Primitive=1) -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 784), float32], Tensor[(128, 784), float32]) -> Tensor[(1, 128), float32] */;
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = fn (%p05: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p12: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1) -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(128), float32]) -> Tensor[(1, 128), float32] */;
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1) -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %6 = %5(%4) /* ty=Tensor[(1, 128), float32] */;
  %7 = fn (%p03: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1) -> Tensor[(1, 128), float32] {
    nn.relu(%p03) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %8 = %7(%6) /* ty=Tensor[(1, 128), float32] */;
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1) -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %11 = %10(%9) /* ty=Tensor[(1, 128), float32] */;
  %12 = fn (%p01: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p11: Tensor[(10, 128), float32] /* ty=Tensor[(10, 128), float32] */, Primitive=1) -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(10, 128), float32]) -> Tensor[(1, 10), float32] */;
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */) /* ty=Tensor[(1, 10), float32] */;
  %14 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, %p1: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1) -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 10), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:148: Build: LabelOps: Output module:
def @main(%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash="dab04952b6e47790", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, %p13: Tensor[(128, 784), float32] /* ty=Tensor[(128, 784), float32] */, Primitive=1, hash="21395bd3c219bfce") -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 784), float32], Tensor[(128, 784), float32]) -> Tensor[(1, 128), float32] */;
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = fn (%p05: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p12: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1, hash="1e855c63ad1bcbb4") -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(128), float32]) -> Tensor[(1, 128), float32] */;
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="692b8d3fc15202f2") -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %6 = %5(%4) /* ty=Tensor[(1, 128), float32] */;
  %7 = fn (%p03: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="bd99c8308cdaf0d5") -> Tensor[(1, 128), float32] {
    nn.relu(%p03) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %8 = %7(%6) /* ty=Tensor[(1, 128), float32] */;
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="544c0a1a67fab49b") -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %11 = %10(%9) /* ty=Tensor[(1, 128), float32] */;
  %12 = fn (%p01: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p11: Tensor[(10, 128), float32] /* ty=Tensor[(10, 128), float32] */, Primitive=1, hash="164daeaa32ba284b") -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(10, 128), float32]) -> Tensor[(1, 10), float32] */;
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */) /* ty=Tensor[(1, 10), float32] */;
  %14 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, %p1: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1, hash="c7ad5bd15b2da050") -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 10), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: LabelOps: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:124: Build: AnnotateMemoryScope: Executing function pass with opt level: 2
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:125: Build: AnnotateMemoryScope: Input module:
def @main(%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash="dab04952b6e47790", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, %p13: Tensor[(128, 784), float32] /* ty=Tensor[(128, 784), float32] */, Primitive=1, hash="21395bd3c219bfce") -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 784), float32], Tensor[(128, 784), float32]) -> Tensor[(1, 128), float32] */;
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = fn (%p05: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p12: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1, hash="1e855c63ad1bcbb4") -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(128), float32]) -> Tensor[(1, 128), float32] */;
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="692b8d3fc15202f2") -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %6 = %5(%4) /* ty=Tensor[(1, 128), float32] */;
  %7 = fn (%p03: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="bd99c8308cdaf0d5") -> Tensor[(1, 128), float32] {
    nn.relu(%p03) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %8 = %7(%6) /* ty=Tensor[(1, 128), float32] */;
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="544c0a1a67fab49b") -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %11 = %10(%9) /* ty=Tensor[(1, 128), float32] */;
  %12 = fn (%p01: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p11: Tensor[(10, 128), float32] /* ty=Tensor[(10, 128), float32] */, Primitive=1, hash="164daeaa32ba284b") -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(10, 128), float32]) -> Tensor[(1, 10), float32] */;
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */) /* ty=Tensor[(1, 10), float32] */;
  %14 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, %p1: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1, hash="c7ad5bd15b2da050") -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 10), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:148: Build: AnnotateMemoryScope: Output module:
def @main(%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash="dab04952b6e47790", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, %p13: Tensor[(128, 784), float32] /* ty=Tensor[(128, 784), float32] */, Primitive=1, hash="21395bd3c219bfce") -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 784), float32], Tensor[(128, 784), float32]) -> Tensor[(1, 128), float32] */;
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = fn (%p05: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p12: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1, hash="1e855c63ad1bcbb4") -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(128), float32]) -> Tensor[(1, 128), float32] */;
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="692b8d3fc15202f2") -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %6 = %5(%4) /* ty=Tensor[(1, 128), float32] */;
  %7 = fn (%p03: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="bd99c8308cdaf0d5") -> Tensor[(1, 128), float32] {
    nn.relu(%p03) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %8 = %7(%6) /* ty=Tensor[(1, 128), float32] */;
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="544c0a1a67fab49b") -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %11 = %10(%9) /* ty=Tensor[(1, 128), float32] */;
  %12 = fn (%p01: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p11: Tensor[(10, 128), float32] /* ty=Tensor[(10, 128), float32] */, Primitive=1, hash="164daeaa32ba284b") -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(10, 128), float32]) -> Tensor[(1, 10), float32] */;
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */) /* ty=Tensor[(1, 10), float32] */;
  %14 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, %p1: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1, hash="c7ad5bd15b2da050") -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 10), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'executor' = graph{"link-params": T.bool(False)}
  'runtime' = cpp
}


[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: AnnotateMemoryScope: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: Running pass RelayToTIRTargetHook
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: GraphExecutorCodegen: RelayToTIRTargetHook: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: Running pass LowerTE
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: GraphExecutorCodegen: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: GraphExecutorCodegen: LowerTE: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:124: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Executing function pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:125: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Input module:
def @main(%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash="dab04952b6e47790", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, %p13: Tensor[(128, 784), float32] /* ty=Tensor[(128, 784), float32] */, Primitive=1, hash="21395bd3c219bfce") -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 784), float32], Tensor[(128, 784), float32]) -> Tensor[(1, 128), float32] */;
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = fn (%p05: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p12: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1, hash="1e855c63ad1bcbb4") -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(128), float32]) -> Tensor[(1, 128), float32] */;
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="692b8d3fc15202f2") -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %6 = %5(%4) /* ty=Tensor[(1, 128), float32] */;
  %7 = fn (%p03: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="bd99c8308cdaf0d5") -> Tensor[(1, 128), float32] {
    nn.relu(%p03) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %8 = %7(%6) /* ty=Tensor[(1, 128), float32] */;
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="544c0a1a67fab49b") -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %11 = %10(%9) /* ty=Tensor[(1, 128), float32] */;
  %12 = fn (%p01: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p11: Tensor[(10, 128), float32] /* ty=Tensor[(10, 128), float32] */, Primitive=1, hash="164daeaa32ba284b") -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(10, 128), float32]) -> Tensor[(1, 10), float32] */;
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */) /* ty=Tensor[(1, 10), float32] */;
  %14 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, %p1: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1, hash="c7ad5bd15b2da050") -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 10), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
}
attributes {
  'constant_memory_pools' = (nullptr)
  'executor' = graph{"link-params": T.bool(False)}
  'main_func_info' = FunctionInfoNode(
workspace_sizes={llvm -keys=cpu : 1024, cuda -keys=cuda,gpu -arch=sm_89 -max_num_threads=1024 -thread_warp_size=32: 1024},
  io_sizes={cuda -keys=cuda,gpu -arch=sm_89 -max_num_threads=1024 -thread_warp_size=32: 0, llvm -keys=cpu : 3176},
  constant_sizes={cuda -keys=cuda,gpu -arch=sm_89 -max_num_threads=1024 -thread_warp_size=32: 0, llvm -keys=cpu : 407080},
  tir_primfuncs={},
  relay_primfuncs={llvm -keys=cpu : fn (%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash="dab04952b6e47790", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, %p13: Tensor[(128, 784), float32] /* ty=Tensor[(128, 784), float32] */, Primitive=1, hash="21395bd3c219bfce") -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 784), float32], Tensor[(128, 784), float32]) -> Tensor[(1, 128), float32] */;
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = fn (%p05: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p12: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1, hash="1e855c63ad1bcbb4") -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(128), float32]) -> Tensor[(1, 128), float32] */;
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="692b8d3fc15202f2") -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %6 = %5(%4) /* ty=Tensor[(1, 128), float32] */;
  %7 = fn (%p03: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="bd99c8308cdaf0d5") -> Tensor[(1, 128), float32] {
    nn.relu(%p03) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %8 = %7(%6) /* ty=Tensor[(1, 128), float32] */;
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="544c0a1a67fab49b") -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %11 = %10(%9) /* ty=Tensor[(1, 128), float32] */;
  %12 = fn (%p01: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p11: Tensor[(10, 128), float32] /* ty=Tensor[(10, 128), float32] */, Primitive=1, hash="164daeaa32ba284b") -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(10, 128), float32]) -> Tensor[(1, 10), float32] */;
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */) /* ty=Tensor[(1, 10), float32] */;
  %14 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, %p1: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1, hash="c7ad5bd15b2da050") -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 10), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
} /* ty=fn (Tensor[(1, 784), float32]) -> Tensor[(1, 10), float32] */
, cuda -keys=cuda,gpu -arch=sm_89 -max_num_threads=1024 -thread_warp_size=32: fn (%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash="dab04952b6e47790", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, %p13: Tensor[(128, 784), float32] /* ty=Tensor[(128, 784), float32] */, Primitive=1, hash="21395bd3c219bfce") -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 784), float32], Tensor[(128, 784), float32]) -> Tensor[(1, 128), float32] */;
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = fn (%p05: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p12: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1, hash="1e855c63ad1bcbb4") -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(128), float32]) -> Tensor[(1, 128), float32] */;
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="692b8d3fc15202f2") -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %6 = %5(%4) /* ty=Tensor[(1, 128), float32] */;
  %7 = fn (%p03: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="bd99c8308cdaf0d5") -> Tensor[(1, 128), float32] {
    nn.relu(%p03) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %8 = %7(%6) /* ty=Tensor[(1, 128), float32] */;
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="544c0a1a67fab49b") -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %11 = %10(%9) /* ty=Tensor[(1, 128), float32] */;
  %12 = fn (%p01: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p11: Tensor[(10, 128), float32] /* ty=Tensor[(10, 128), float32] */, Primitive=1, hash="164daeaa32ba284b") -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(10, 128), float32]) -> Tensor[(1, 10), float32] */;
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */) /* ty=Tensor[(1, 10), float32] */;
  %14 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, %p1: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1, hash="c7ad5bd15b2da050") -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 10), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
} /* ty=fn (Tensor[(1, 784), float32]) -> Tensor[(1, 10), float32] */
})
  'runtime' = cpp
  'workspace_memory_pools' = (nullptr)
}


One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPrefetch
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TextureFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferShapeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferStrideLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ThreadScopePropagate
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferBindUnwrapper
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ApplyLayoutTransforms
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlattener
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.AssertSimplifier
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerCrossThreadReduction
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerInitBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.PlanAndUpdateBufferAllocationLocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ConvertBlocksToOpaque
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LiftThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ManifestSharedMemoryLocalStage
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CompactBufferAllocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerAutoCopy
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnifyThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerMatchBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPermutedLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectSoftwarePipeline
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TransformMmaBufferLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerOpaqueBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FlattenBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FP8ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BF16ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.NarrowDataType
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LoopPartition
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.VectorizeLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectVirtualThread
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectDoubleBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageRewrite
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnrollLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RenormalizeSplitPattern
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RewriteUnsafeSelect
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.HoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InsertHoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CommonSubexprElimTIR
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPrefetch
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TextureFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferShapeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferStrideLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ThreadScopePropagate
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferBindUnwrapper
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ApplyLayoutTransforms
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlattener
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.AssertSimplifier
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerCrossThreadReduction
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerInitBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.PlanAndUpdateBufferAllocationLocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ConvertBlocksToOpaque
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LiftThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ManifestSharedMemoryLocalStage
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CompactBufferAllocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerAutoCopy
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnifyThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerMatchBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPermutedLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectSoftwarePipeline
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TransformMmaBufferLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerOpaqueBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FlattenBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FP8ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BF16ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.NarrowDataType
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LoopPartition
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.VectorizeLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectVirtualThread
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectDoubleBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageRewrite
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnrollLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RenormalizeSplitPattern
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RewriteUnsafeSelect
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.HoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InsertHoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CommonSubexprElimTIR
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPrefetch
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TextureFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferShapeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferStrideLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ThreadScopePropagate
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferBindUnwrapper
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ApplyLayoutTransforms
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlattener
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.AssertSimplifier
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerCrossThreadReduction
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerInitBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.PlanAndUpdateBufferAllocationLocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ConvertBlocksToOpaque
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LiftThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ManifestSharedMemoryLocalStage
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CompactBufferAllocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerAutoCopy
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnifyThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerMatchBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPermutedLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectSoftwarePipeline
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TransformMmaBufferLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerOpaqueBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FlattenBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FP8ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BF16ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.NarrowDataType
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LoopPartition
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.VectorizeLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectVirtualThread
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectDoubleBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageRewrite
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnrollLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RenormalizeSplitPattern
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RewriteUnsafeSelect
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.HoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InsertHoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CommonSubexprElimTIR
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPrefetch
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TextureFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferShapeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferStrideLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ThreadScopePropagate
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferBindUnwrapper
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ApplyLayoutTransforms
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlattener
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.AssertSimplifier
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerCrossThreadReduction
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerInitBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.PlanAndUpdateBufferAllocationLocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ConvertBlocksToOpaque
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LiftThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ManifestSharedMemoryLocalStage
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CompactBufferAllocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerAutoCopy
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnifyThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerMatchBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPermutedLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectSoftwarePipeline
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TransformMmaBufferLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerOpaqueBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FlattenBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FP8ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BF16ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.NarrowDataType
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LoopPartition
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.VectorizeLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectVirtualThread
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectDoubleBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageRewrite
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnrollLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RenormalizeSplitPattern
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RewriteUnsafeSelect
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.HoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InsertHoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CommonSubexprElimTIR
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPrefetch
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TextureFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlatten
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferShapeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferStrideLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ThreadScopePropagate
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferBindUnwrapper
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ApplyLayoutTransforms
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlattener
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.AssertSimplifier
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerCrossThreadReduction
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerInitBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.PlanAndUpdateBufferAllocationLocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ConvertBlocksToOpaque
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LiftThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ManifestSharedMemoryLocalStage
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CompactBufferAllocation
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerAutoCopy
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnifyThreadBinding
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerMatchBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPermutedLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectSoftwarePipeline
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TransformMmaBufferLayout
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerOpaqueBlock
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FlattenBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FP8ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BF16ComputeLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.NarrowDataType
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LoopPartition
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.VectorizeLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectVirtualThread
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectDoubleBuffer
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageRewrite
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnrollLoop
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RenormalizeSplitPattern
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RewriteUnsafeSelect
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.HoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InsertHoistIfThenElse
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CommonSubexprElimTIR
[17:23:46] /home/zeonfaiho/tvm/src/relay/ir/transform.cc:148: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Output module:
def @main(%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash="dab04952b6e47790", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = (%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */);
  %1 = call_lowered(@tvmgen_default_fused_nn_dense, %0, metadata={"relay_attrs"={__dict__={"Primitive"=1, "hash"="21395bd3c219bfce"}}, "all_prim_fn_vars"=['tvmgen_default_fused_nn_dense']});
  %2 = (%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */);
  %3 = call_lowered(@tvmgen_default_fused_nn_bias_add, %2, metadata={"relay_attrs"={__dict__={"Primitive"=1, "hash"="1e855c63ad1bcbb4"}}, "all_prim_fn_vars"=['tvmgen_default_fused_nn_bias_add']});
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True);
  %5 = device_copy(%4, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))));
  %6 = (%5,);
  %7 = call_lowered(@tvmgen_default_fused_nn_relu, %6, metadata={"relay_attrs"={__dict__={"Primitive"=1, "hash"="bd99c8308cdaf0d5"}}, "all_prim_fn_vars"=['tvmgen_default_fused_nn_relu']});
  %8 = on_device(%7, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True);
  %9 = device_copy(%8, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))));
  %10 = (%9, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */);
  %11 = call_lowered(@tvmgen_default_fused_nn_dense_1, %10, metadata={"relay_attrs"={__dict__={"Primitive"=1, "hash"="164daeaa32ba284b"}}, "all_prim_fn_vars"=['tvmgen_default_fused_nn_dense_1']});
  %12 = (%11, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */);
  call_lowered(@tvmgen_default_fused_nn_bias_add_1, %12, metadata={"relay_attrs"={__dict__={"Primitive"=1, "hash"="c7ad5bd15b2da050"}}, "all_prim_fn_vars"=['tvmgen_default_fused_nn_bias_add_1']})
}
attributes {
  'constant_memory_pools' = (nullptr)
  'executor' = graph{"link-params": T.bool(False)}
  'main_func_info' = FunctionInfoNode(
workspace_sizes={llvm -keys=cpu : 1024, cuda -keys=cuda,gpu -arch=sm_89 -max_num_threads=1024 -thread_warp_size=32: 1024},
  io_sizes={cuda -keys=cuda,gpu -arch=sm_89 -max_num_threads=1024 -thread_warp_size=32: 0, llvm -keys=cpu : 3176},
  constant_sizes={cuda -keys=cuda,gpu -arch=sm_89 -max_num_threads=1024 -thread_warp_size=32: 0, llvm -keys=cpu : 407080},
  tir_primfuncs={},
  relay_primfuncs={llvm -keys=cpu : fn (%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash="dab04952b6e47790", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, %p13: Tensor[(128, 784), float32] /* ty=Tensor[(128, 784), float32] */, Primitive=1, hash="21395bd3c219bfce") -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 784), float32], Tensor[(128, 784), float32]) -> Tensor[(1, 128), float32] */;
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = fn (%p05: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p12: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1, hash="1e855c63ad1bcbb4") -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(128), float32]) -> Tensor[(1, 128), float32] */;
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="692b8d3fc15202f2") -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %6 = %5(%4) /* ty=Tensor[(1, 128), float32] */;
  %7 = fn (%p03: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="bd99c8308cdaf0d5") -> Tensor[(1, 128), float32] {
    nn.relu(%p03) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %8 = %7(%6) /* ty=Tensor[(1, 128), float32] */;
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="544c0a1a67fab49b") -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %11 = %10(%9) /* ty=Tensor[(1, 128), float32] */;
  %12 = fn (%p01: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p11: Tensor[(10, 128), float32] /* ty=Tensor[(10, 128), float32] */, Primitive=1, hash="164daeaa32ba284b") -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(10, 128), float32]) -> Tensor[(1, 10), float32] */;
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */) /* ty=Tensor[(1, 10), float32] */;
  %14 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, %p1: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1, hash="c7ad5bd15b2da050") -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 10), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
} /* ty=fn (Tensor[(1, 784), float32]) -> Tensor[(1, 10), float32] */
, cuda -keys=cuda,gpu -arch=sm_89 -max_num_threads=1024 -thread_warp_size=32: fn (%data {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))}: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash="dab04952b6e47790", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) -> Tensor[(1, 10), float32] {
  %0 = fn (%p06: Tensor[(1, 784), float32] /* ty=Tensor[(1, 784), float32] */, %p13: Tensor[(128, 784), float32] /* ty=Tensor[(128, 784), float32] */, Primitive=1, hash="21395bd3c219bfce") -> Tensor[(1, 128), float32] {
    nn.dense(%p06, %p13, units=None) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 784), float32], Tensor[(128, 784), float32]) -> Tensor[(1, 128), float32] */;
  %1 = %0(%data, meta[relay.Constant][0] /* ty=Tensor[(128, 784), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %2 = fn (%p05: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p12: Tensor[(128), float32] /* ty=Tensor[(128), float32] */, Primitive=1, hash="1e855c63ad1bcbb4") -> Tensor[(1, 128), float32] {
    nn.bias_add(%p05, %p12) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(128), float32]) -> Tensor[(1, 128), float32] */;
  %3 = %2(%1, meta[relay.Constant][1] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(1, 128), float32] */;
  %4 = on_device(%3, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %5 = fn (%p04: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="692b8d3fc15202f2") -> Tensor[(1, 128), float32] {
    device_copy(%p04, src_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %6 = %5(%4) /* ty=Tensor[(1, 128), float32] */;
  %7 = fn (%p03: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="bd99c8308cdaf0d5") -> Tensor[(1, 128), float32] {
    nn.relu(%p03) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %8 = %7(%6) /* ty=Tensor[(1, 128), float32] */;
  %9 = on_device(%8, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), constrain_result=True) /* ty=Tensor[(1, 128), float32] */;
  %10 = fn (%p02: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, Primitive=1, hash="544c0a1a67fab49b") -> Tensor[(1, 128), float32] {
    device_copy(%p02, src_virtual_device=VirtualDevice(device_type=2, virtual_device_id=0, target=Target(id=56274ef74bb0, kind='cuda', keys={'cuda', 'gpu'}, attrs={'thread_warp_size': 32, 'max_num_threads': 1024, 'arch': "sm_89"}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'}))), dst_virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=56274f39d390, kind='llvm', keys={'cpu'}, host=Target(id=56274f337c30, kind='llvm', keys={'cpu'})))) /* ty=Tensor[(1, 128), float32] */
  } /* ty=fn (Tensor[(1, 128), float32]) -> Tensor[(1, 128), float32] */;
  %11 = %10(%9) /* ty=Tensor[(1, 128), float32] */;
  %12 = fn (%p01: Tensor[(1, 128), float32] /* ty=Tensor[(1, 128), float32] */, %p11: Tensor[(10, 128), float32] /* ty=Tensor[(10, 128), float32] */, Primitive=1, hash="164daeaa32ba284b") -> Tensor[(1, 10), float32] {
    nn.dense(%p01, %p11, units=None) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 128), float32], Tensor[(10, 128), float32]) -> Tensor[(1, 10), float32] */;
  %13 = %12(%11, meta[relay.Constant][2] /* ty=Tensor[(10, 128), float32] */) /* ty=Tensor[(1, 10), float32] */;
  %14 = fn (%p0: Tensor[(1, 10), float32] /* ty=Tensor[(1, 10), float32] */, %p1: Tensor[(10), float32] /* ty=Tensor[(10), float32] */, Primitive=1, hash="c7ad5bd15b2da050") -> Tensor[(1, 10), float32] {
    nn.bias_add(%p0, %p1) /* ty=Tensor[(1, 10), float32] */
  } /* ty=fn (Tensor[(1, 10), float32], Tensor[(10), float32]) -> Tensor[(1, 10), float32] */;
  %14(%13, meta[relay.Constant][3] /* ty=Tensor[(10), float32] */) /* ty=Tensor[(1, 10), float32] */
} /* ty=fn (Tensor[(1, 784), float32]) -> Tensor[(1, 10), float32] */
})
  'runtime' = cpp
  'workspace_memory_pools' = (nullptr)
}


[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: Running pass InferType
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: GraphExecutorCodegen: InferType: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: GraphExecutorCodegen: Running pass tir.ExtractPrimFuncConstants
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: GraphExecutorCodegen: tir.ExtractPrimFuncConstants: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.calculate_allocated_bytes
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.calculate_allocated_bytes: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerVtcmAlloc
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.BindTarget
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.VerifyMemory
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.VerifyMemory: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.AnnotateEntryFunc
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.AnnotateEntryFunc: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.ThreadSync
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.ThreadSync
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.MergeDynamicSharedMemoryAllocations
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.ThreadSync
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.InferFragment
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerThreadAllreduce
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.AnnotateDeviceRegions
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.SplitHostDevice
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.SplitHostDevice: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.SplitHostDevice: tir.ConvertSSA: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.MakePackedAPI
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.MakePackedAPI: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.FP8StorageLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.BF16StorageLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerDeviceKernelLaunch
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.LowerDeviceKernelLaunch: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.Filter
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.BindTarget
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerTVMBuiltin
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerCustomDatatypes
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerIntrin
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerDeviceStorageAccessInfo
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.CombineContextCall
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.Filter
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.BindTarget
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerWarpMemory
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerCustomDatatypes
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerDeviceStorageAccessInfo
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerIntrin
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.calculate_allocated_bytes
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.calculate_allocated_bytes: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerVtcmAlloc
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.BindTarget
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.VerifyMemory
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.VerifyMemory: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.AnnotateEntryFunc
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.AnnotateEntryFunc: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.ThreadSync
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.ThreadSync
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.MergeDynamicSharedMemoryAllocations
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.ThreadSync
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.InferFragment
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerThreadAllreduce
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.AnnotateDeviceRegions
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.SplitHostDevice
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.SplitHostDevice: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.SplitHostDevice: tir.ConvertSSA: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.MakePackedAPI
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.MakePackedAPI: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.FP8StorageLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.BF16StorageLegalize
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerDeviceKernelLaunch
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:416: Build: tir.LowerDeviceKernelLaunch: Executing module pass with opt level: 0
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.Filter
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.BindTarget
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerTVMBuiltin
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerCustomDatatypes
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerIntrin
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerDeviceStorageAccessInfo
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.CombineContextCall
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.Filter
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.BindTarget
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerWarpMemory
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.Simplify
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerCustomDatatypes
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerDeviceStorageAccessInfo
[17:23:46] /home/zeonfaiho/tvm/src/ir/transform.cc:477: Build: Running pass tir.LowerIntrin
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/arith/int_set.cc:527: Warning: cannot evaluate set type tir.Call
[17:23:46] /home/zeonfaiho/tvm/src/runtime/memory/naive_allocator.h:47: allocate 3136 B, used memory 3136 B
[17:23:46] /home/zeonfaiho/tvm/src/runtime/memory/naive_allocator.h:47: allocate 401408 B, used memory 404544 B
[17:23:46] /home/zeonfaiho/tvm/src/runtime/memory/naive_allocator.h:47: allocate 512 B, used memory 405056 B
[17:23:46] /home/zeonfaiho/tvm/src/runtime/memory/naive_allocator.h:47: allocate 512 B, used memory 405568 B
[17:23:46] /home/zeonfaiho/tvm/src/runtime/memory/naive_allocator.h:47: allocate 512 B, used memory 406080 B
[17:23:46] /home/zeonfaiho/tvm/src/runtime/memory/naive_allocator.h:47: allocate 512 B, used memory 512 B
[17:23:46] /home/zeonfaiho/tvm/src/runtime/memory/naive_allocator.h:47: allocate 512 B, used memory 1024 B
[17:23:46] /home/zeonfaiho/tvm/src/runtime/memory/naive_allocator.h:47: allocate 5120 B, used memory 411200 B
[17:23:46] /home/zeonfaiho/tvm/src/runtime/memory/naive_allocator.h:47: allocate 40 B, used memory 411240 B
[17:23:46] /home/zeonfaiho/tvm/src/runtime/threading_backend.cc:343: Warning: more than two frequencies detected! Forced big_count_ to 16
Original main function:
free_var %data: Tensor[(1, 784), float32];
%0 = nn.dense(%data, meta[relay.Constant][0], units=None);
%1 = nn.bias_add(%0, meta[relay.Constant][1]);
%2 = nn.relu(%1);
%3 = nn.dense(%2, meta[relay.Constant][2], units=None);
nn.bias_add(%3, meta[relay.Constant][3])

New main function:
free_var %data: Tensor[(1, 784), float32];
%0 = nn.dense(%data, meta[relay.Constant][0], units=None);
%1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0));
%2 = nn.bias_add(%1, meta[relay.Constant][1]);
%3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0));
%4 = nn.relu(%3);
%5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0));
%6 = nn.dense(%5, meta[relay.Constant][2], units=None);
%7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0));
%8 = nn.bias_add(%7, meta[relay.Constant][3]);
on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0))

Transformed IRModule: def @main(%data: Tensor[(1, 784), float32]) {
  %0 = nn.dense(%data, meta[relay.Constant][0], units=None);
  %1 = on_device(%0, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0));
  %2 = nn.bias_add(%1, meta[relay.Constant][1]);
  %3 = on_device(%2, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0));
  %4 = nn.relu(%3);
  %5 = on_device(%4, virtual_device=VirtualDevice(device_type=2, virtual_device_id=0));
  %6 = nn.dense(%5, meta[relay.Constant][2], units=None);
  %7 = on_device(%6, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0));
  %8 = nn.bias_add(%7, meta[relay.Constant][3]);
  on_device(%8, virtual_device=VirtualDevice(device_type=1, virtual_device_id=0))
}


Output: [[-28.304369   -35.135296   -20.574156   -20.601543   -17.1196
    2.7829108  -15.253119     0.21254028  -4.941827     8.81127   ]]
Prediction: Ankle boot
